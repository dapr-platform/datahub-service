## 6.1.2 数据底座架构设计

![附图32. 数据底座架构设计](图片链接)

园区数据底座架构设计以数据为核心，通过构建层次化、模块化和安全高效的数据管理与服务体系，将数据资源转化为数据资产，进而支撑智慧园区的运营和发展。园区数据底座架构可以分为以下三个层次：

### 一、原始数据汇聚层

原始数据汇聚层主要负责园区内各类原始数据的采集、加工及入库过程，构成数据底座的基础。在这一层，通过数据抽取、清洗、标准化和建模等过程，将来自园区弱电智能化系统、园区信息化系统及物联设备的海量数据转换为结构化、标准化的格式，为进一步的分析和应用打下坚实的基础。原始数据汇聚层包含的核心功能模块包括：

- **数据采集与预处理模块**：主要实现园区内各种数据源的广泛接入和实时采集。该模块负责对接各系统采集原始数据，并进行初步的数据处理和转化，以便于后续的数据存储和分析。经过数据采集与处理的原始数据将写入数据存储
- **数据处理模块**：主要实现数据的进一步加工处理和分析任务。该模块将基于用户对数据的加工需求，将采集到的原始数据精细化加工为具有数据分析价值的数据资产。
- **数据存储模块**：用于为初步处理及精细化加工后的数据提供稳定、高效的存储解决方案。该模块负责数据的长期存储、管理和保护，确保数据的安全、可靠，同时支持数据的快速检索和查询。

### 二、数据资产加工层

数据资产加工层是数据底座架构的核心部分，负责将原始数据汇聚层提供的数据转化为高价值的数据资产，并对数据资产进行控制和管理。为了实现这一转化过程，数据资产加工层需要具备以下能力：

- **数据资产中心**：数据资产中心是由一系列主题库组成的，它作为智慧园区核心数据资产的一种表达。这些主题库按照不同的业务领域和分析目的组织数据，使得数据资产更加易于理解及访问。
- **数据治理模块**：用于确保数据资产的质量、安全性和合规性。该模块涵盖了数据访问控制、数据质量管控、元数据管理、数据监控等一系列管控能力。通过数据治理，数据组织者能够确保数据的准确性、一致性和可用性。
- **数据运维模块**：数据运维模块是确保数据底座架构稳定运行的关键支撑部分。该模块通过一系列运维管理功能，如权限管理、日志管理、安全管理等，从而保障整体数据底座的高效性、安全性和可靠性。

### 三、数据开放共享层

数据开放共享层着重于数据的开放与共享，对外提供服务，推动数据价值的最大化输出。在这一层，通过 API 管理、数据订阅分发、数据格式转化和数据安全传输等机制，实现数据的开放共享，从而实现园区内不同部门和团队之间以及与外部合作伙伴的数据共享与协作。

## 6.1.3 数据集成原则与范围

### 6.1.3.1 数据集成原则

数据底座作为园区信息化底座的核心组件，负责数据的存储、处理与共享。然而，这并不意味着园区内所有信息化系统及弱电智能化系统的数据均需统一存储于数据底座之中。若数据仅被存储而未被有效利用，则只会导致存储资源产生不必要消耗。因此，在设计园区信息化底座时，必须确立一套明确标准，用以判定哪些数据应纳入数据底座进行集中管理。对此，通服陕西院建议按如下原则进行考虑：

- 与园区经营分析相关的数据，包括其依赖的原始数据均应纳入数据底座集中管理，从而为后续经营分析专题构建积累足够的数据素材。
- 与后续园区 IOC 场景相关的数据，应纳入数据底座集中管理，以便为未来 IOC 场景构建积累足够的数据素材。
- 从建设周期看，对于那些消费场景的建设明显滞后于生产场景的数据，应纳入数据底座集中管理。这样可以避免在后续构建数据消费场景时，与数据生产方产生额外的沟通协调风险与额外开发工作量。

### 6.1.3.2 数据集成范围

![附图33. 园区数据底座-数据集成范围](图片链接)

基于上述数据集成原则，通服陕西院建议以下系统/应用需与数据底座进行数据同步，将相应数据资源存储至数据底座中进行集中管理。

**表格16. 园区数据底座-数据集成范围**

| 序号 | 数据来源 | 数据集成范围 |
| --- | --- | --- |
| 1 | 园区统一票务 | 包括订单数据，订单数据的关联信息（如活动基本信息、演出基本信息等），用于构建经营收入类数据分析挖掘应用场景。 |
| 2 | 园区线上商城 | 包括订单数据、订单数据的关联信息（如商品基本信息、用户评价等）、库存数据，用于构建经营收入类、采购决策类数据分析挖掘应用场景。 |
| 3 | 园区交通配套 | 停车缴费数据，用于构建经营收入类数据分析挖掘应用场景。 |
| 4 | 招采管理 | 包括采购计划数据、询比价数据、招投标数据等，用于构建采购决策分析类数据分析挖掘应用场景。 |
| 5 | 供应商管理 | 包括供应商基本信息、供应商资质数据、供应商评价数据等，用于构建经营成本类、采购决策类数据分析挖掘应用场景。 |
| 6 | 合同管理 | 包括合同基本信息、合同执行数据、合同履约数据等，用于构建经营成本类、采购决策类数据分析挖掘应用场景。 |
| 7 | 资产管理 | 包括资产基本信息、资产状态数据、资产盘点数据等，用于构建经营成本类、采购决策类数据分析挖掘应用场景，同时也用于支撑设备运行监测、集中指挥调度类数据综合呈现应用场景。 |
| 8 | 物业管理 | 包括安防事件数据、报检报修事件数据、保洁事件数据、绿植养护事件数据、排值班数据，同时也用于支撑园区安全防范类、设备运行监测、园区运营管理类数据综合呈现应用场景。 |
| 9 | 聚合支付 | 包括交易数据和订单数据的关联信息，用于构建经营收入类、消费热点类数据分析挖掘应用场景。 |
| 10 | 业财转换 | 包括已开票应收单、未开票应收单、已收票应付单等业务单据数据，用于构建经营收入类、消费热点类、经营成本类、采购决策类数据分析挖掘应用场景。 |
| 11 | 客户/商户管理 | 客户/商户数据，用于构建经营收入类、消费热点类数据分析挖掘应用场景，同时也用于支撑设备运行监测类数据综合呈现应用场景。 |
| 12 | 会员积分管理 | 包括会员信息数据和会员积分数据，用于构建消费热点分析类数据分析挖掘应用场景。 |
| 13 | 集中指挥调度 | 包括预案数据、预案流程演练数据、预案流程执行数据，用于支撑集中指挥调度类数据综合呈现应用场景。 |
| 14 | AI 算力平台 | 视频监控 AI 分析事件，用于支撑园区运营管理类数据综合呈现应用场景。 |
| 15 | 物联网平台 | 包括用能分析数据、能耗监测数据、机电设备监测数据、门禁管理数据、停车管理数据、紧急告警数据，用于支撑园区安全防范类、设备监测类、园区运营管理类数据综合呈现应用场景。 |

## 6.1.4 数据底座核心功能

### 6.1.4.1 数据采集与预处理

#### 数据源管理

识别、注册和管理内外部的所有数据源，包括关系型数据库、非关系型数据库、文件系统、API 等，确保所有数据源都能被适当地访问和监控。数据底座应支持以下数据源管理功能：

- **数据源注册**：允许用户将不同的数据源（如数据库、API、文件等）注册到数据底座中，便于统一管理和访问。
- **数据源连接配置**：提供界面或工具用于配置数据源的连接参数，如服务器地址、端口、用户名、密码等，确保数据底座能够正确连接到各个数据源。
- **数据源监控**：实时监控数据源的运行状况，包括数据更新频率、数据质量、连接状态等。

#### 数据抽取

对于数据底座而言，数据抽取能力至关重要。它是实现数据集中管控的起点，直接影响数据底座的数据内容与数据质量，进而影响数据分析与决策支持能力。数据底座应支持以下目前业内常见的数据抽取方式：

- **直接数据库连接**：通过直接连接到对端数据库，使用 SQL 查询或存储过程来抽取数据。这种方式适用于关系型数据库和一些非关系型数据库，同时需要对端系统开放足够的数据访问权限，一般适用于同一个业务域内部不同系统之间的数据交互场景。
- **API 调用**：利用应用程序编程接口（API）从内部或外部系统中获取数据。可广泛适用于内部系统、跨业务域的内部系统、以及与互联网服务之间的数据交互场景。
- **文件采集**：支持从各种格式的文件（如 CSV、Excel、XML、JSON 等以及非结构化数据）中导入数据。这种方式适用于大批量非实时性的数据交换和批量数据处理。
- **消息队列**：通过消息队列（如 Kafka、RabbitMQ）订阅和消费数据。这种方式适用于实时数据处理和分布式系统的数据集成。
- **数据推送**：数据通信双方约定数据订阅与推送规则后，通过数据推送机制实现数据交互，一般用于外部系统在数据更新时主动将数据发送到数据底座。
- **手动数据输入**：提供用户界面，允许用户手动输入数据，适用于小规模或非自动化的数据采集需求。
- **数据同步工具**：使用数据同步工具来同步不同系统之间的数据，确保数据一致性。这种采集方式一般用于实现异构数据库之间的数据同步场景。

#### 数据清洗

数据清洗是指使用一系列的数据清洗规则和算法，识别和纠正数据中的错误、重复和不一致性。数据底座应支持在数据抽取的过程中同步对数据内容进行清洗。数据底座应支持的数据清洗功能具体包括：

- **处理缺失数据**：识别数据中的缺失值，并根据业务规则和数据分析需求选择适当的填充方法，以确保数据的完整性。
- **添加默认值**：对于预期应有值但实际缺失的字段，根据数据类型和业务逻辑添加合理的默认值。
- **删除不完整的行**：移除关键信息缺失或数据不完整的记录行。
- **删除不完整的列**：如果某列数据大量缺失，可根据业务规则自动删除指定列。
- **规范化数据类型**：将数据转换为统一的格式和类型，例如将日期字符串转换为日期类型，将数字字符串转换为数值类型。
- **对人工录入数据进行数据变换**：针对人工录入的数据，进行必要的转换和调整，如统一单位、格式化文本、转换编码等。
- **重命名列名**：对列名进行标准化和重命名，使其更加清晰、直观和符合命名规范。
- **删除空行**：移除数据中完全为空或仅包含空白字符的行。
- **删除非法数据**：识别并移除不符合业务规则、逻辑错误或明显异常的数据记录，如负数的年龄、未来的日期等。
- **删除重复数据**：检测并移除数据中的重复记录，确保每条数据的唯一性。

#### 数据标准化

数据标准化是指将不同格式和结构的数据转换成统一的标准格式，有助于整合来自不同源的数据。数据标准化的过程实际上是通过对原始数据进行一系列的数据转化，从而形成统一数据格式。数据底座应支持的数据转化功能具体包括：

- **值映射**：对源表和目标表的字段进行映射
- **统计**：对某一个字段求和、求平均、求最大或最小值作为一个新字段的值
- **计算**：将字段进行加、减、乘、除作为新字段的值
- **拆分字段**：将原有字段拆分成新的字段
- **合并**：将来自两个不同的步骤的数据流进行合并
- **分组**：根据指定字段进行分组
- **行转列**：行列互转
- **排序**：利用指定的字段排序，升序或者降序
- **过滤**：根据指定条件，对数据过滤
- **增加常量**：添加常量到数据流中

#### 数据模型管理

数据模型用于定义数据的结构、关系和约束。数据模型管理负责管理和优化园区数据底座所包含的所有数据模型。数据底座应支持的数据模型管理功能具体包括：

- **数据结构查阅**：允许用户查看现有数据模型的详细结构，包括数据表、字段名称、数据类型、字段长度等。
- **数据结构导入**：支持从外部文件或系统导入数据结构定义，如 XML、JSON 或数据库导出文件，实现快速构建数据模型。
- **数据结构更新**：提供工具或界面用于修改现有数据结构，包括添加、删除或修改字段，调整数据类型等。
- **数据关系查阅**：允许用户查看数据模型中定义的数据关系，如外键、关联表等。
- **数据关系创建**：支持用户定义新的数据关系，包括建立表之间的关联、设置外键等。
- **数据关系更新**：提供工具或界面用于修改现有数据关系。
- **数据约束查阅**：允许用户查看数据模型中的数据约束，如唯一性约束、非空约束等。
- **数据约束创建**：支持用户为数据模型添加新的数据约束。
- **数据约束更新**：提供工具或界面用于修改或删除现有的数据约束。

#### 数据质量管理

数据质量管理是指对数据采集质量进行定期检查的机制，通过监控数据采集过程中的各个环节，及时发现和纠正数据问题，确保数据的准确性和完整性。数据底座应支持的数据质量管理功能具体包括：

- **数据采集连续性检查**：监控数据采集的实时状态，及时发现并处理数据采集中断或延迟的问题。
- **数据采集完整性检查**：对采集过程中收集到的数据进行完整性检查，确保其涵盖所有预定的数据元素。如发现有数据项缺失，应支持自动标记相关采集项，并根据预先设定的规则决定是触发补采流程或提示人工检查。
- **数据采集准确性检查**：对采集过程中收集到的数据进行准确性检查，确保各数据项或数据字段的内容符合预期值。如发现异常数据，应支持自动标记相关采集项，并根据预先设定的规则决定是触发补采流程或提示人工检查。
- **数据自动补采**：当检测到数据缺失或数据异常时，自动触发数据补采流程，重新从数据源采集缺失或错误的数据。
- **数据质量告警**：当数据质量不符合预设标准时，可自动触发告警，通知管理人员进行检查和修正。

### 6.1.4.2 数据处理

#### 数据实时处理

数据实时处理是指对实时数据流进行即时处理的能力，适用于需要快速响应的场景，如安防监控类场景。为了实现数据实时处理，数据底座应当具备流式数据处理引擎，并支持以下功能特性：

- 支持以秒级和分钟级为粒度对在线数据的实时和准实时处理。
- 具备处理高吞吐量的实时数据流的能力，确保在数据量激增时仍能保持稳定的处理性能。
- 支持多源数据的实时融合处理，可在同一个实时数据处理任务中接入多种数据源。
- 支持将实时处理后的数据写入至各数据主题库中。
- 提供灵活的调度机制，允许用户根据业务需求定制实时任务的执行时间和频率。
- 提供详细的任务日志和任务监控功能，便于用户跟踪离线任务的执行状态。

#### 数据离线处理

数据离线处理是指对非实时、批量数据进行处理的能力，适用于需要处理大量累积数据的场景，如历史数据分析、批量报告生成等。离线处理允许系统在非高峰时段执行资源密集型任务，以优化资源使用。为了实现数据离线处理，数据底座应当具备批处理数据处理引擎，并支持以下功能特性：

- 具备处理大规模批量数据的能力，确保在处理海量数据时仍能保持稳定的处理性能。
- 支持多源数据的融合处理，可在同一个离线数据处理任务中整合多种数据源的数据。
- 支持将离线处理后的数据写入至各数据主题库中。
- 提供灵活的调度机制，允许用户根据业务需求定制离线任务的执行时间和频率。
- 提供详细的任务日志和任务监控功能，便于用户跟踪离线任务的执行状态。

### 6.1.4.3 数据存储

#### 数据基础库

基础库用于存储未经加工的原始数据。这些数据来源于各类信息化系统、弱电智能化系统或第三方信息化系统，保持了数据的原始格式和完整性。基础库的主要目的是确保所有采集到的数据都能被完整保存，并为后续的数据处理与分析提供可靠的基础。

#### 数据主题库

主题库是按照特定主题或业务领域组织的数据集合，支持复杂的查询和分析，使业务用户能够根据自己的需求快速访问和分析数据。与基础库不同，主题库中的数据已经过转换和加工，形成了更有意义的数据视图，专注于服务特定的业务场景或支持特定决策过程。

在构建智慧园区的数据底座时，提前确定数据资产的主题库是一项至关重要的步骤。明确数据资产主题库可使数据底座以一种结构化的方式来组织和管理数据。每个主题库都将围绕特定的业务领域或功能需求来组织数据，通过主题库的划分，数据底座能够更有效地支持数据分析、报告和决策制定。此外，提前规划主题库还有助于简化数据集成过程，降低数据冗余，提高数据的重用性，从而为智慧园区带来更高效的运营。

确定数据资产的主题库应当基于园区的具体业态和业务需求。本园区业态多样，包括企业文化馆、多功能会议中心、精品酒店、经济型酒店、员工宿舍等。这些业态涉及多种业务运营和管理需求，如客户服务、设施管理、能源监控、安全防护、商业运营、财务管理等。因此，数据资产的主题库划分应当反映这些业态的特定需求，确保数据资产能够支持园区的后续运营。

基于上述思路，通服陕西院建议考虑按照如下方式划分数据底座的数据资产主题库：

**表格17. 数据资产主题库划分方式建议**

| 序号 | 数据分类 | 数据主题 | 数据主题域内容描述 |
| --- | --- | --- | --- |
| 1 | 人员数据 | 会员数据 | 包括海底捞会员基本信息、会员积分数据等。 |
| 2 | 资产数据 | 资产数据 | 包括资产基本信息、资产状态数据、资产盘点数据等 |
| 3 | 供应链数据 | 招采数据 | 包括采购计划数据、询比价数据、招投标数据等 |
| 4 |  | 供应商数据 | 包括供应商基本信息、供应商资质数据、供应商评价数据等 |
| 5 |  | 合同数据 | 包括合同基本信息、合同执行数据、合同履约数据等 |
| 6 | 园区运行数据 | 机电运行数据 | 包括各类机电设备基本信息、运行状态、告警信息等数据。 |
| 7 |  | 能源管理数据 | 包括用能分析数据、能耗监测数据。 |
| 8 |  | 综合安防数据 | 包括门禁管理数据、停车管理数据、紧急告警数据、视频监控 AI 分析事件等。 |
| 9 |  | 物业数据 | 包括安防事件数据、报检报修事件数据、保洁事件数据、绿植养护事件数据、排值班数据等 |
| 10 | 园区运营数据 | 电商交易数据 | 线上商城交易分析数据。 |
| 11 |  | 票务交易数据 | 统一票务交易分析数据。 |
| 12 |  | 园区支付交易数据 | 园区聚合支付交易与停车缴费分析数据。 |
| 13 |  | 客户/商户数据 | 包括客户基本信息、商户基本信息等数据。 |
| 14 | 应急安全数据 | 集中指挥调度数据 | 包括应急预案信息、预案演练数据、指挥调度数据等。 |

### 6.1.4.4 数据治理

#### 访问控制管理

访问控制管理是数据治理中的核心环节，负责确保只有经过授权的用户或系统可以访问特定数据资源。它通过实施一系列策略、流程和技术手段，对数据的访问权限进行精细化控制，防止未经授权的访问和数据泄露。数据底座应支持的访问控制管理功能具体包括：

- **用户身份认证**：验证试图访问数据的用户或系统的身份，确保其合法性。
- **用户权限分配**：根据用户角色分配相应的数据访问权限，实现最小权限原则。
- **应用访问控制列表（ACL）**：维护并更新访问控制列表，明确指定哪些系统可以访问哪些数据资源。

#### 数据质量管理

衡量数据质量的指标体系有很多，典型的指标包括完整性(数据是否缺失)、规范性(数据是否按照要求的规则存储)、一致性(数据的值是否存在信息含义上的冲突)、准确性(数据是否错误)、唯一性(数据是否是重复的)、时效性(数据是否按照时间的要求进行上传)。

序号	数据来源	数据集成范围
1	园区统一票务	包括订单数据，订单数据的关联信息（如活动基本信息、演出基本信息等），用于构建经营收入类数据分析挖掘应用场景。
 

2	园区线上商城	包括订单数据、订单数据的关联信息（如商品基本信息、用户评价等）、库存数据，用于构建经营收入类、采购决策类数据分析挖掘应用场景。
3	园区交通配套	停车缴费数据，用于构建经营收入类数据分析挖掘应用场景。
4	招采管理	包括采购计划数据、询比价数据、招投标数据等，用于构建采购决策分析类数据分析挖掘应用场景。
5	供应商管理	包括供应商基本信息、供应商资质数据、供应商评价数据等，用于构建经营成本类、采购决策类数据分析挖掘应用场景。
6	合同管理	包括合同基本信息、合同执行数据、合同履约数据等，用于构建经营成本类、采购决策类数据分析挖掘应用场景。
7	资产管理	包括资产基本信息、资产状态数据、资产盘点数据等，用于构建经营成本类、采购决策类数据分析挖掘应用场景，同时也用于支撑设备运行监测、集中指挥调度类数据综合呈现应用场景。
8	物业管理	包括安防事件数据、报检报修事件数据、保洁事件数据、绿植养护事件数据、排值班数据，同时也用于支撑园区安全防范类、设备运行监测、园区运营管理类数据综合呈现应用场景。
9	聚合支付	包括交易数据和订单数据的关联信息，用于构建经营收入类、消费热点类数据分析挖掘应用场景。
10	业财转换	包括已开票应收单、未开票应收单、已收票应付单等业务单据数据，用于构建经营收入类、消费热点类、经营成本类、采购决策类数据分析挖掘应用场景。
11	客户/商户管理	客户/商户数据，用于构建经营收入类、消费热点类数据分析挖掘应用场景，同时也用于支撑设备运行监测类数据综合呈现应用场景。
12	会员积分管理	包括会员信息数据和会员积分数据，用于构建消费热点分析类数据分析挖掘应用场景。
13	集中指挥调度	包括预案数据、预案流程演练数据、预案流程执行数据，用于支撑集中指挥调度类数据综合呈现应用场
 

		景。
14	AI 算力平台	视频监控 AI 分析事件，用于支撑园区运营管理类数据综合呈现应用场景。
15	物联网平台	包括用能分析数据、能耗监测数据、机电设备监测数据、门禁管理数据、停车管理数据、紧急告警数据，用于支撑园区安全防范类、设备监测类、园区运营管理类数据综合呈现应用场景。
6.1.4	数据底座核心功能

6.1.4.1	数据采集与预处理

	数据源管理

识别、注册和管理内外部的所有数据源，包括关系型数据库、非关系型数据库、文件系统、API 等，确保所有数据源都能被适当地访问和监控。数据底座应支持以下数据源管理功能：
	数据源注册：允许用户将不同的数据源（如数据库、API、文件等）注册到数据底座中，便于统一管理和访问。
	数据源连接配置：提供界面或工具用于配置数据源的连接参数，如服务器地址、端口、用户名、密码等，确保数据底座能够正确连接到各个数据源。
	数据源监控：实时监控数据源的运行状况，包括数据更新频率、数据质量、连接状态等。
	数据抽取

对于数据底座而言，数据抽取能力至关重要。它是实现数据集中管控的起点，直接影响数据底座的数据内容与数据质量，进而影响数据分析与决策支持能力。数据底座应支持以下目前业内常见的数据抽取方式：
	直接数据库连接：通过直接连接到对端数据库，使用 SQL 查询或存储过程来抽取数据。这种方式适用于关系型数据库和一些非关系型数据库，同时需要对端系统开放
 
足够的数据访问权限，一般适用于同一个业务域内部不同系统之间的数据交互场景。
	API 调用：利用应用程序编程接口（API）从内部或外部系统中获取数据。可广泛适用于内部系统、跨业务域的内部系统、以及与互联网服务之间的数据交互场景。
	文件采集：支持从各种格式的文件（如 CSV、Excel、XML、JSON 等以及非结构化数据）中导入数据。这种方式适用于大批量非实时性的数据交换和批量数据处理。
	消息队列：通过消息队列（如 Kafka、RabbitMQ）订阅和消费数据。这种方式适用于实时数据处理和分布式系统的数据集成。
	数据推送：数据通信双方约定数据订阅与推送规则后，通过数据推送机制实现数据交互，一般用于外部系统在数据更新时主动将数据发送到数据底座。
	手动数据输入：提供用户界面，允许用户手动输入数据，适用于小规模或非自动化的数据采集需求。
	数据同步工具：使用数据同步工具来同步不同系统之间的数据，确保数据一致性。这种采集方式一般用于实现异构数据库之间的数据同步场景。
	数据清洗

数据清洗是指使用一系列的数据清洗规则和算法，识别和纠正数据中的错误、重复和不一致性。数据底座应支持在数据抽取的过程中同步对数据内容进行清洗。数据底座应支持的数据清洗功能具体包括：
	处理缺失数据：识别数据中的缺失值，并根据业务规则和数据分析需求选择适当的填充方法，以确保数据的完整性。
	添加默认值：对于预期应有值但实际缺失的字段，根据数据类型和业务逻辑添加合理的默认值。
	删除不完整的行：移除关键信息缺失或数据不完整的记录行。
	删除不完整的列：如果某列数据大量缺失，可根据业务规则自动删除指定列。
	规范化数据类型：将数据转换为统一的格式和类型，例如将日期字符串转换为日期类型，将数字字符串转换为数值类型。
	对人工录入数据进行数据变换：针对人工录入的数据，进行必要的转换和调整，如统一单位、格式化文本、转换编码等。
	重命名列名：对列名进行标准化和重命名，使其更加清晰、直观和符合命名规范。
 
	删除空行：移除数据中完全为空或仅包含空白字符的行。
	删除非法数据：识别并移除不符合业务规则、逻辑错误或明显异常的数据记录，如负数的年龄、未来的日期等。
	删除重复数据：检测并移除数据中的重复记录，确保每条数据的唯一性。

	数据标准化

数据标准化是指将不同格式和结构的数据转换成统一的标准格式，有助于整合来自不同源的数据。数据标准化的过程实际上是通过对原始数据进行一系列的数据转化，从而形成统一数据格式。数据底座应支持的数据转化功能具体包括：
	值映射：对源表和目标表的字段进行映射
	统计：对某一个字段求和、求平均、求最大或最小值作为一个新字段的值
	计算：将字段进行加、减、乘、除作为新字段的值
	拆分字段：将原有字段拆分成新的字段
	合并：将来自两个不同的步骤的数据流进行合并
	分组：根据指定字段进行分组
	行转列：行列互转
	排序：利用指定的字段排序，升序或者降序
	过滤：根据指定条件，对数据过滤
	增加常量：添加常量到数据流中

	数据模型管理

数据模型用于定义数据的结构、关系和约束。数据模型管理负责管理和优化园区数据底座所包含的所有数据模型。数据底座应支持的数据模型管理功能具体包括：
	数据结构查阅：允许用户查看现有数据模型的详细结构，包括数据表、字段名称、数据类型、字段长度等。
	数据结构导入：支持从外部文件或系统导入数据结构定义，如 XML、JSON 或数据库导出文件，实现快速构建数据模型。
	数据结构更新：提供工具或界面用于修改现有数据结构，包括添加、删除或修改字段，调整数据类型等。
 
	数据关系查阅：允许用户查看数据模型中定义的数据关系，如外键、关联表等。
	数据关系创建：支持用户定义新的数据关系，包括建立表之间的关联、设置外键等。
	数据关系更新：提供工具或界面用于修改现有数据关系。
	数据约束查阅：允许用户查看数据模型中的数据约束，如唯一性约束、非空约束等。
	数据约束创建：支持用户为数据模型添加新的数据约束。
	数据约束更新：提供工具或界面用于修改或删除现有的数据约束。

	数据质量管理

数据质量管理是指对数据采集质量进行定期检查的机制，通过监控数据采集过程中的各个环节，及时发现和纠正数据问题，确保数据的准确性和完整性。数据底座应支持的数据质量管理功能具体包括：
	数据采集连续性检查：监控数据采集的实时状态，及时发现并处理数据采集中断或延迟的问题。
	数据采集完整性检查：对采集过程中收集到的数据进行完整性检查，确保其涵盖所有预定的数据元素。如发现有数据项缺失，应支持自动标记相关采集项，并根据预先设定的规则决定是触发补采流程或提示人工检查。
	数据采集准确性检查：对采集过程中收集到的数据进行准确性检查，确保各数据项或数据字段的内容符合预期值。如发现异常数据，应支持自动标记相关采集项，并根据预先设定的规则决定是触发补采流程或提示人工检查。
	数据自动补采：当检测到数据缺失或数据异常时，自动触发数据补采流程，重新从数据源采集缺失或错误的数据。
	数据质量告警：当数据质量不符合预设标准时，可自动触发告警，通知管理人员进行检查和修正。

6.1.4.2	数据处理

	数据实时处理

数据实时处理是指对实时数据流进行即时处理的能力，适用于需要快速响应的场景，如安防监控类场景。为了实现数据实时处理，数据底座应当具备流式数据处理引擎，并支持以
 
下功能特性：

	支持以秒级和分钟级为粒度对在线数据的实时和准实时处理。
	具备处理高吞吐量的实时数据流的能力，确保在数据量激增时仍能保持稳定的处理性能。
	支持多源数据的实时融合处理，可在同一个实时数据处理任务中接入多种数据源。
	支持将实时处理后的数据写入至各数据主题库中。
	提供灵活的调度机制，允许用户根据业务需求定制实时任务的执行时间和频率。
	提供详细的任务日志和任务监控功能，便于用户跟踪离线任务的执行状态。

	数据离线处理

数据离线处理是指对非实时、批量数据进行处理的能力，适用于需要处理大量累积数据的场景，如历史数据分析、批量报告生成等。离线处理允许系统在非高峰时段执行资源密集型任务，以优化资源使用。为了实现数据离线处理，数据底座应当具备批处理数据处理引擎，并支持以下功能特性：
	具备处理大规模批量数据的能力，确保在处理海量数据时仍能保持稳定的处理性能。
	支持多源数据的融合处理，可在同一个离线数据处理任务中整合多种数据源的数据。
	支持将离线处理后的数据写入至各数据主题库中。
	提供灵活的调度机制，允许用户根据业务需求定制离线任务的执行时间和频率。
	提供详细的任务日志和任务监控功能，便于用户跟踪离线任务的执行状态。

6.1.4.3	数据存储

	数据基础库

基础库用于存储未经加工的原始数据。这些数据来源于各类信息化系统、弱电智能化系统或第三方信息化系统，保持了数据的原始格式和完整性。基础库的主要目的是确保所有采集到的数据都能被完整保存，并为后续的数据处理与分析提供可靠的基础。
	数据主题库

主题库是按照特定主题或业务领域组织的数据集合，支持复杂的查询和分析，使业务用
 
户能够根据自己的需求快速访问和分析数据。与基础库不同，主题库中的数据已经过转换和加工，形成了更有意义的数据视图，专注于服务特定的业务场景或支持特定决策过程。
在构建智慧园区的数据底座时，提前确定数据资产的主题库是一项至关重要的步骤。明确数据资产主题库可使数据底座以一种结构化的方式来组织和管理数据。每个主题库都将围绕特定的业务领域或功能需求来组织数据，通过主题库的划分，数据底座能够更有效地支持数据分析、报告和决策制定。此外，提前规划主题库还有助于简化数据集成过程，降低数据冗余，提高数据的重用性，从而为智慧园区带来更高效的运营。
确定数据资产的主题库应当基于园区的具体业态和业务需求。本园区业态多样，包括企业文化馆、多功能会议中心、精品酒店、经济型酒店、员工宿舍等。这些业态涉及多种业务运营和管理需求，如客户服务、设施管理、能源监控、安全防护、商业运营、财务管理等。因此，数据资产的主题库划分应当反映这些业态的特定需求，确保数据资产能够支持园区的后续运营。
基于上述思路，通服陕西院建议考虑按照如下方式划分数据底座的数据资产主题库：
表格17.	数据资产主题库划分方式建议
序号	数据分类	数据主题	数据主题域内容描述
1	人员数据	会员数据	包括海底捞会员基本信息、会员积分数据等。
2	资产数据	资产数据	包括资产基本信息、资产状态数据、资产盘点数据等
3	供应链数据	招采数据	包括采购计划数据、询比价数据、招投标数据等
4		供应商数据	包括供应商基本信息、供应商资质数据、供应商评价数据等
5		合同数据	包括合同基本信息、合同执行数据、合同履约数据等
6	园区运行数据	机电运行数据	包括各类机电设备基本信息、运行状态、告警信息等数据。
7		能源管理数据	包括用能分析数据、能耗监测数据。
8		综合安防数据	包括门禁管理数据、停车管理数据、紧急告警数据、视频监控 AI 分析事件等。
 

9		物业数据	包括安防事件数据、报检报修事件数据、保洁事件数据、绿植养护事件数据、排值班数据等
10	园区运营数据	电商交易数据	线上商城交易分析数据。
11		票务交易数据	统一票务交易分析数据。
12		园区支付交易数据	园区聚合支付交易与停车缴费分析数据。
13		客户/商户数据	包括客户基本信息、商户基本信息等数据。
14	应急安全数据	集中指挥调度数据	包括应急预案信息、预案演练数据、指挥调度数据等。

6.1.4.4	数据治理

	访问控制管理

访问控制管理是数据治理中的核心环节，负责确保只有经过授权的用户或系统可以访问特定数据资源。它通过实施一系列策略、流程和技术手段，对数据的访问权限进行精细化控制，防止未经授权的访问和数据泄露。数据底座应支持的访问控制管理功能具体包括：
	用户身份认证：验证试图访问数据的用户或系统的身份，确保其合法性。
	用户权限分配：根据用户角色分配相应的数据访问权限，实现最小权限原则。
	应用访问控制列表（ACL）：维护并更新访问控制列表，明确指定哪些系统可以访问哪些数据资源。
	数据质量管理

衡量数据质量的指标体系有很多，典型的指标包括完整性(数据是否缺失)、规范性(数据是否按照要求的规则存储)、一致性(数据的值是否存在信息含义上的冲突)、准确性(数据是否错误)、唯一性(数据是否是重复的)、时效性(数据是否按照时间的要求进行上传)。
数据质量管理是指从数据完整性、规范性、一致性、准确性、唯一性、时效性等多个角度对入库数据质量进行监控与分析。数据底座应支持的数据质量管理功能具体包括：
	数据完整性管理：实时检查数据集中是否存在缺失值或空字段，确保所有必要的数据都被完整收集和记录。
 
	数据规范性管理：验证数据是否符合预定义的格式、类型和约束条件，确保数据存储和表示的规范性。
	数据一致性管理：检查跨系统或不同来源的数据之间是否存在逻辑冲突或不一致之处，确保数据在不同环境下的统一性和连贯性。
	数据准确性管理：通过比对源数据与目标数据，以及利用业务规则校验，识别并纠正数据中的错误或异常值，确保数据反映真实情况
	数据唯一性管理：检测数据中的重复记录，确保每条数据在数据集中都是唯一的。
	数据时效性管理：跟踪数据的时间戳或更新频率，确保数据能够按照要求的时间进行上传和更新。
	数据质量报告：生成数据质量报告，向管理层和相关部门展示数据质量状况和改进成果。
	元数据管理

元数据是描述数据的数据。元数据按用途不同分为技术元数据、业务元数据和管理元数据。技术元数据：描述数据底座中技术领域相关概念、关系和规则的数据，包括数据底座内对象和数据结构的定义源数据到目的数据的映射、数据转换的描述等。业务元数据：描述数据底座中业务领域相关概念、关系和规则的数据，包括业务术语、信息分类、指标、统计口径等。管理元数据：描述数据底座中管理领域相关概念、关系、规则的数据，主要包括人员角色、岗位职责、管理流程等信息。
元数据管理是数据资产管理的重要基础，是为获得高质量的、整合的元数据而进行的规划、实施与控制行为。数据底座的元数据管理应支持以下具体功能：
	元数据查询：应支持按元数据名称、元数据类别的查询，展示内容应包括元数据编码元数据名称、元数据类型、元数据详细内容、创建时间、修改时间等关键信息。
	据表使用情况，从访问频次和业务需求角度出发，进行数据冷热度分析。
	数据资产地图：通过对各类元数据的梳理和加工，实现不同来源的元数据有效集成形成数据资产地图。
	数据监控

实时监控数据的状态和性能，确保数据服务的稳定性和可靠性。数据底座支持的数据监
 
控功能具体包括：

	数据访问频次监控：实时跟踪和记录各主题库数据被访问的次数，分析访问频次的变化趋势。
	数据访问来源监控：监控数据访问的来源地址和设备信息，分析不同访问来源的数据访问频次。
	数据存储空间监控：实时监测数据存储空间的使用情况，包括已用空间、剩余空间和空间使用率
	数据脱敏

数据脱敏旨在保护敏感信息不被泄露，同时满足数据共享和使用的需求。通过对数据进行脱敏处理，可以有效地屏蔽个人隐私、商业机密等敏感信息，降低数据泄露风险。数据脱敏主要包括以下方面：
	敏感信息识别：自动识别数据中的敏感信息，如个人身份信息、财务信息、联系方式等。
	脱敏策略制定：根据数据敏感度和使用需求，制定相应的脱敏策略，如数据遮蔽、数据替换、数据加密等。
	脱敏规则应用：将脱敏策略应用于数据集，对敏感信息进行脱敏处理，确保数据的安全性和合规性。
	脱敏效果验证：验证脱敏后的数据是否满足安全要求，同时保证数据的可用性和一致性。
	数据审计

数据审计管理涉及对数据访问和使用情况进行跟踪、记录和分析的过程。它确保数据操作的合规性、可追溯性，并有助于检测和防范数据滥用或违规行为。数据底座应支持全面的审计功能，具体包括：
	审计日志收集：自动收集数据访问、修改、删除等操作的日志信息，确保所有数据活动都有记录可查。
	合规性检查与报告：定期生成详细的合规性报告，验证数据处理活动是否符合相关
 
的法律法规和行业标准。

6.1.4.5	数据运维

	用户管理

对数据底座中所有用户的生命周期进行管理和维护，包括用户账户的创建、修改、禁用和删除等操作。同时用户管理应当提供用户登录身份认证功能，可通过实施严格的身份验证和用户认证机制，确保只有授权用户能够访问系统。数据底座用户管理模块应支持通过 OAuth2 协议或其它单点登录技术与园区统一账号系统进行单点登录集成。
	权限管理

定义和控制用户或系统在数据底座内的操作权限，确保每个用户只能访问和操作其职责范围内允许的数据和功能。权限管理应支持基于角色的访问控制（RBAC），可以精确限定每个用户的权限范围，保障数据的安全性和隐私性。
	日志管理

对系统中发生的各类事件进行全面记录和分析，确保所有活动均可追溯。数据底座应支持详细的日志记录，可以追踪到每一个操作的时间、执行者、影响范围等信息，为故障排查、性能优化和安全审计提供有力支持。
	备份管理

对数据底座的数据和配置进行定期备份，并确保在发生故障或数据丢失时能够迅速恢复，以保护数据的安全性和完整性。数据底座应支持对关键主题库、关键数据项进行备份，可通 过设置定时备份策略实现关键数据自动备份。
	自监控管理

数据底座应具备自我监测和预警的能力，能够实时跟踪自身的运行状态，识别潜在的问题并自动发出告警通知。数据底座应支持对自身的服务器状态、核心应用状态、存储组件状态、数据缓存组件状态等进行实时监控，支持将报警事件以短信或飞书接口方式推送至数据底座管理员。
 
6.1.4.6	数据共享服务

	数据目录管理

数据目录管理指通过一个集中的数据目录，使数据使用方能够发现、理解和访问他们所需的数据，从而促进数据的透明度和可发现性。数据底座的数据目录管理应支持的具体功能包括：
	数据基础库目录：提供对数据底座中所有基础数据集的描述，包括数据集的来源、结构、数据示例等信息，以便于用户快速定位和理解基础数据集。
	数据主题库目录：提供对数据底座中所有主题数据集的描述，包括数据集的来源、元数据、数据所有者、数据示例等信息，以便于用户快速定位和理解基础数据集。
	数据使用申请：支持数据使用方通过资源申请或订阅的方式获取基础库数据资源与主题库数据资源。
	数据使用授权：支持通过服务授权机制对数据使用方提出的数据使用申请进行审批与授权。
	数据 API

数据 API 是数据底座提供数据共享服务的三种方式之一。数据使用者可以通过调用数据 API 从数据底座中实时抽取所需的数据。数据底座提供数据服务 API 的创建、发布、维护和监控，为数据服务的标准化访问提供了框架，支持数据使用方通过 API 访问数据。
	数据订阅

数据订阅是数据底座提供数据共享服务的三种方式之一。数据使用者可以订阅特定的数据更新。当数据更新时，数据底座可自动将这些更新分发给订阅者，确保他们能够及时获取最新信息。这种机制支持了数据的实时或近实时共享，适用于需要频繁数据更新的场景。
	库表同步

库表同步是数据底座提供数据共享服务的三种方式之一。通过库表同步，数据底座能够实现与外部数据库或数据仓库的表级别数据同步。库表同步应支持多种同步策略，如全量同步和增量同步，以及数据转换和映射功能，以适应不同数据结构和格式的要求。
 
	数据安全传输

数据安全传输用于确保数据在传输过程中的安全性和完整性，包括使用加密技术、安全协议（如 SSL/TLS）以及其他网络安全措施来保护数据不被未授权访问或篡改。
	数据鉴权认证

数据鉴权认证主要用以验证用户或系统的身份，并授权其访问特定的数据资源，包括登录认证、权限检查和访问控制列表（ACL）的管理。

6.1.5	非功能性需求设计

6.1.5.1	系统性能要求

数据底座应能够高效处理大规模数据，保证在高峰时段仍能提供稳定的性能表现。以下为对数据底座性能的具体量化要求：
	数据存储周期：主题库数据与基础库数据至少应存储 3 年。
	API 响应时间：99%的 API 调用请求应在 200 毫秒内完成响应。
	查询响应时间：复杂查询的平均响应时间不超过 500 毫秒。
	数据导入速度：每秒至少可批量导入 10000 条记录。
	界面响应时间：页面加载时间不超过 2 秒，操作响应时间不超过 1 秒。
	并发用户数：支持至少 200 个并发用户进行日常操作。

6.1.5.2	系统可扩展性要求

系统可扩展性用以确保数据底座能够适应未来业务增长和技术发展。以下为对数据底座可扩展性的具体要求：
	系统应采用模块化设计，便于未来功能扩展和升级。
	系统应支持水平扩展，可通过增加服务器或资源来提升数据处理与存储能力。
	系统应支持对新增数据源类型进行扩展支撑。
	系统应支持平滑升级，避免因升级导致的服务中断。
 
6.1.5.3	系统高可用性要求

系统高可用性用以确保系统在各种情况下都能提供持续、稳定的服务，即使在硬件故障、软件错误或网络中断等异常情况下也能保持正常运行。数据底座高可用性具体要求如下：
	服务可用率：系统应保证全年服务可用率达到 99.95%以上，即每年的非计划停机时间不超过 4.38 小时，以确保业务连续性和用户体验。
	容错机制：系统应设计有冗余组件和自动故障转移机制，以应对硬件或软件故障。关键组件如数据库等应具备热备份能力，确保单点故障不会导致整个系统的不可用。
	监控与告警：系统应集成实时监控和智能告警功能，对关键性能指标（KPI）进行持续跟踪，并在出现异常时及时通知管理员采取措施，预防潜在问题影响服务。

6.1.5.4	系统运行环境要求

数据底座应可在多种环境下稳定运行，满足不同场景下的部署需求。具体要求包括：

	支持私有化部署：提供完整的私有化部署方案，支持在园区数据中心独立部署和管理数据底座。
	支持虚拟化运行环境：兼容主流虚拟化平台（如 VMware、KVM 等），可在虚拟机中运行数据底座。
	通用数据库支持：兼容多种关系型和非关系型数据库。
	操作系统兼容性：支持各发行版 Linux 操作系统，确保数据底座能够在不同的操作系统环境中稳定运行。
